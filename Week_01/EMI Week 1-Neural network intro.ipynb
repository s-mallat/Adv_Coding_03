{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8a_TDA0eOtn"
   },
   "source": [
    "# Week 1 \n",
    "# Intro to working with neural nets in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this the first time, you will need to install keras if you haven't done it previously!\n",
    "\n",
    "The easiest way to do this is to open a terminal/console window and do the following:\n",
    "\n",
    "First, if you have created a new environment (e.g., called \"emi\") for this class, activate it. (If you haven't created an environment then skip this step):\n",
    "\n",
    "`conda activate emi`\n",
    "\n",
    "Then, use conda to install keras:\n",
    "\n",
    "`conda install -c anaconda keras`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iX-_2g9yeOtp"
   },
   "outputs": [],
   "source": [
    "# Now do your imports\n",
    "import numpy as np\n",
    "from keras.models import Sequential #base keras model\n",
    "from keras.layers import Dense, Activation #dense = fully connected layer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import h5py # for saving a trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nnZkKibeOtp"
   },
   "source": [
    "## Part 1: A very, very simple example\n",
    "\n",
    "Can we train a single, 1-input neuron to learn the function output = 5 * input ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4Z9r0N7FeOtp"
   },
   "outputs": [],
   "source": [
    "#Let's make a training dataset with 3 examples\n",
    "x_train = np.array([[2], [1], [-3]]) #Input values for each of our 3 training examples\n",
    "y_train = np.array([10, 5, -15]) #Output values (aka \"targets\") for each of our 3 training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dn4euxfOeOtq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the network using keras\n",
    "num_neurons = 1\n",
    "model = Sequential() #the basic keras model class\n",
    "model.add(Dense(num_neurons, input_dim = 1)) #add a \"layer\" of 1 neuron, which has 1 input value. This will compute a weighted sum, with no additional activation function.\n",
    "model.summary() #print out info about this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BYpjyqL4eOtq"
   },
   "outputs": [],
   "source": [
    "#Set some training parameters\n",
    "#use stochastic gradient descent (pretty standard optimisation method) with a learning rate of 0.1 (why not?)\n",
    "sgd = SGD(learning_rate=0.1) #Note that in previous versions the \"learning_rate\" parameter was titled \"lr\" instead\n",
    "\n",
    "#optimise the mean squared error (i.e., the mean of the squared difference between the model's output and the training target, for each training example)\n",
    "#    This is a fairly standard choice when predicting a real value (as opposed to a binary class of 0 or 1)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M9ZhtLB7eOtr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3804057],\n",
       "       [ 1.6902028],\n",
       "       [-5.0706086]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the current model on each of the training examples (i.e., using the inputs to calculate the neuron output)\n",
    "model.predict(x_train) #outputs garbage as it's not trained yet: It's computing output = w1 * input + w0 using random values of w0 and w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lCmiA1QzeOtr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 51.1222\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2272\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4906e-06\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9978e-08\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0116e-11\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8729d94fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model!\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hov7Xe4seOtr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.],\n",
       "       [  5.],\n",
       "       [-15.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now run it:\n",
    "model.predict(x_train) #Does it produce values similar to y_train? It should..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eSRHqntKeOtr",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.000000e+01],\n",
       "       [-6.390492e-08],\n",
       "       [ 2.500000e+01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can (and should) run it on some new data, too... \n",
    "new_values = np.array([[-10], [0], [5]]) # 3 new \"data points\"\n",
    "\n",
    "#Does it output 5 * x for each new value x ?\n",
    "model.predict(new_values) #be careful to read this using scientific notation ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-bjy2e7reOts",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.]], dtype=float32), array([-6.390492e-08], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the model's weights! We'll see (1) the weight for the input, and (2) the weight for the bias\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U6LlIeXEeOts"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 51.4623\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8643\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4106\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallymallat/opt/anaconda3/envs/emi2/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2621\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1678\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1074\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0687\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0440\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0281\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0115\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8729e85970>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perhaps try with a new dataset in which our training example output (target) values are np.array([11, 6, -14])?\n",
    "y_train_new = np.array([11, 6, -14])\n",
    "model = Sequential() #the basic model class\n",
    "model.add(Dense(num_neurons, input_dim = 1)) #add a \"layer\" of 1 neuron, which has 1 input value. This will compute a weighted sum, with no additional activation function.\n",
    "model.summary()\n",
    "sgd = SGD(lr=0.1) \n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "model.fit(x_train, y_train_new, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e08iTiACeOts"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.]], dtype=float32), array([0.9648157], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() #Notice weight is 5 and bias is now 1 (approximately), encoding the function output = input * 5 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Week 4.2-Neural network intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
